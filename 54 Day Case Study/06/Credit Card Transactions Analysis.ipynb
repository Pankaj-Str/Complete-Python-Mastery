{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1804b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Step 1: Load and Clean Data\n",
    "# Load dataset\n",
    "df = pd.read_csv('credit_card_transactions.csv')\n",
    "\n",
    "# Show first 5 rows\n",
    "print(\"Step 1.1: First 5 rows of dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# Check dataset details\n",
    "print(\"\\nStep 1.2: Dataset Shape:\", df.shape)\n",
    "print(\"\\nStep 1.3: Column Names:\", df.columns.tolist())\n",
    "print(\"\\nStep 1.4: Summary Statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nStep 1.5: Missing Values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Fill missing values\n",
    "for column in df.columns:\n",
    "    if df[column].dtype == 'object':\n",
    "        df[column].fillna('Unknown', inplace=True)\n",
    "    else:\n",
    "        df[column].fillna(df[column].median(), inplace=True)\n",
    "\n",
    "# Verify no missing values\n",
    "print(\"\\nStep 1.6: Missing Values After Cleaning:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Convert Transaction_Date to datetime\n",
    "df['Transaction_Date'] = pd.to_datetime(df['Transaction_Date'], errors='coerce')\n",
    "df['Year'] = df['Transaction_Date'].dt.year\n",
    "df['Month'] = df['Transaction_Date'].dt.month\n",
    "df['Day'] = df['Transaction_Date'].dt.day\n",
    "print(\"\\nStep 1.7: DataFrame Info After Date Conversion:\")\n",
    "print(df.info())\n",
    "\n",
    "# Step 2: Filter Transactions\n",
    "# January 2024 transactions\n",
    "jan_2024 = df[(df['Year'] == 2024) & (df['Month'] == 1)]\n",
    "print(\"\\nStep 2.1: Transactions in January 2024:\")\n",
    "print(jan_2024.head())\n",
    "\n",
    "# High-value online transactions\n",
    "high_online = df[(df['Amount'] > 1000) & (df['Transaction_Type'] == 'Online')]\n",
    "print(\"\\nStep 2.2: Transactions Over $1000 (Online):\")\n",
    "print(high_online.head())\n",
    "\n",
    "# Approved transactions\n",
    "approved = df[df['Transaction_Status'] == 'Approved']\n",
    "print(\"\\nStep 2.3: Approved Transactions:\")\n",
    "print(approved.head())\n",
    "\n",
    "# Step 3: Create New Features\n",
    "# Add Discounted_Amount (5% off for >$500)\n",
    "df['Discounted_Amount'] = df['Amount'].apply(lambda x: x * 0.95 if x > 500 else x)\n",
    "print(\"\\nStep 3.1: First 5 Rows with Discounted_Amount:\")\n",
    "print(df[['Amount', 'Discounted_Amount']].head())\n",
    "\n",
    "# Categorize Amount\n",
    "df['Amount_Category'] = pd.cut(df['Amount'], \n",
    "                              bins=[-float('inf'), 100, 500, float('inf')],\n",
    "                              labels=['Low', 'Medium', 'High'])\n",
    "print(\"\\nStep 3.2: First 5 Rows with Amount_Category:\")\n",
    "print(df[['Amount', 'Amount_Category']].head())\n",
    "\n",
    "# Drop Merchant if >30% missing\n",
    "if df['Merchant'].isnull().mean() > 0.3:\n",
    "    df.drop(columns=['Merchant'], inplace=True)\n",
    "    print(\"\\nStep 3.3: Dropped Merchant column (too many missing values).\")\n",
    "else:\n",
    "    print(\"\\nStep 3.3: Merchant column retained.\")\n",
    "\n",
    "# Step 4: Aggregate Data\n",
    "# Total amount by category\n",
    "total_by_category = df.groupby('Category')['Amount'].sum().reset_index()\n",
    "print(\"\\nStep 4.1: Total Amount by Category:\")\n",
    "print(total_by_category)\n",
    "\n",
    "# Declined transactions by payment mode\n",
    "declined_by_mode = df[df['Transaction_Status'] == 'Declined'].groupby('Payment_Mode').size().reset_index(name='Declined_Count')\n",
    "print(\"\\nStep 4.2: Declined Transactions by Payment Mode:\")\n",
    "print(declined_by_mode)\n",
    "\n",
    "# Top 5 merchants\n",
    "if 'Merchant' in df.columns:\n",
    "    top_merchants = df['Merchant'].value_counts().head(5).reset_index()\n",
    "    top_merchants.columns = ['Merchant', 'Transaction_Count']\n",
    "    print(\"\\nStep 4.3: Top 5 Merchants:\")\n",
    "    print(top_merchants)\n",
    "else:\n",
    "    print(\"\\nStep 4.3: Merchant column not available.\")\n",
    "\n",
    "# Average amount by location\n",
    "avg_by_location = df.groupby('Location')['Amount'].mean().reset_index()\n",
    "print(\"\\nStep 4.4: Average Amount by Location:\")\n",
    "print(avg_by_location)\n",
    "\n",
    "# Step 5: Detect Fraud\n",
    "# Customers with >10 transactions daily\n",
    "df['Date'] = df['Transaction_Date'].dt.date\n",
    "daily_transactions = df.groupby(['Customer_ID', 'Date']).size().reset_index(name='Transaction_Count')\n",
    "fraud_customers = daily_transactions[daily_transactions['Transaction_Count'] > 10]\n",
    "print(\"\\nStep 5.1: Customers with >10 Daily Transactions:\")\n",
    "print(fraud_customers)\n",
    "\n",
    "# Same customer, different locations within 5 minutes\n",
    "df_sorted = df.sort_values(['Customer_ID', 'Transaction_Date'])\n",
    "df_sorted['Time_Diff'] = df_sorted.groupby('Customer_ID')['Transaction_Date'].diff().dt.total_seconds() / 60\n",
    "df_sorted['Location_Change'] = df_sorted.groupby('Customer_ID')['Location'].shift() != df_sorted['Location']\n",
    "location_anomalies = df_sorted[(df_sorted['Time_Diff'].notnull()) & (df_sorted['Time_Diff'] <= 5) & (df_sorted['Location_Change'])]\n",
    "print(\"\\nStep 5.2: Same Customer, Different Locations (5 Min):\")\n",
    "print(location_anomalies[['Customer_ID', 'Transaction_Date', 'Location', 'Time_Diff']])\n",
    "\n",
    "# High-risk transactions (> $5000, Online)\n",
    "high_risk = df[(df['Amount'] > 5000) & (df['Transaction_Type'] == 'Online')]\n",
    "print(\"\\nStep 5.3: High-Risk Transactions (> $5000, Online):\")\n",
    "print(high_risk)\n",
    "\n",
    "# Step 6: Merge with Customer Data\n",
    "try:\n",
    "    customer_info = pd.read_csv('customer_info.csv')\n",
    "    merged_df = pd.merge(df, customer_info, on='Customer_ID', how='inner')\n",
    "    age_bins = [0, 18, 30, 50, 100]\n",
    "    age_labels = ['<18', '18-30', '31-50', '>50']\n",
    "    merged_df['Age_Group'] = pd.cut(merged_df['Age'], bins=age_bins, labels=age_labels, include_lowest=True)\n",
    "    avg_by_age = merged_df.groupby('Age_Group')['Amount'].mean().reset_index()\n",
    "    print(\"\\nStep 6.1: Average Amount by Age Group:\")\n",
    "    print(avg_by_age)\n",
    "except FileNotFoundError:\n",
    "    print(\"\\nStep 6.1: customer_info.csv not found.\")\n",
    "\n",
    "# Step 7: Visualize Insights\n",
    "# Bar chart: Total amount by category\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(data=total_by_category, x='Category', y='Amount', palette='viridis')\n",
    "plt.title('Total Transaction Amount by Category')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Total Amount ($)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/bar_chart_category.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Heatmap: Correlation\n",
    "df_encoded = df.copy()\n",
    "df_encoded['Status_Code'] = df_encoded['Transaction_Status'].astype('category').cat.codes\n",
    "df_encoded['Mode_Code'] = df_encoded['Payment_Mode'].astype('category').cat.codes\n",
    "correlation_matrix = df_encoded[['Amount', 'Status_Code', 'Mode_Code']].corr()\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.title('Correlation Heatmap for Credit Card Transactions Analysis')\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/heatmap_correlation.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
